{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Effective Agents (with Pydantic AI)\n",
    "\n",
    "Examples for the agentic workflows discussed in\n",
    "[Building Effective Agents](https://www.anthropic.com/research/building-effective-agents)\n",
    "by [Erik Schluntz](https://github.com/eschluntz) and [Barry Zhang](https://github.com/ItsBarryZ)\n",
    "of Anthropic, inspired, ported and adapted from the\n",
    "[code samples](https://github.com/anthropics/anthropic-cookbook/tree/main/patterns/agents)\n",
    "by the authors using [Pydantic AI](https://ai.pydantic.dev/).\n",
    "\n",
    "## Evaluator - Optimizer\n",
    "Examples are based from [Intellectronica - Building Effective Agents with Pydantic AI](https://github.com/intellectronica/building-effective-agents-with-pydantic-ai)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt\n",
    "from IPython.display import clear_output ; clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available AI models:\n",
      "['azure:gpt-4o', 'azure:gpt-4o-mini']\n",
      "\n",
      "Using AI model: azure:gpt-4o\n",
      "Configuring Azure AI Foundry model: gpt-4o at https://agent-workshop-yrkd.cognitiveservices.azure.com/\n"
     ]
    }
   ],
   "source": [
    "from util import initialize, show\n",
    "AI_MODEL = initialize()\n",
    "\n",
    "from typing import List, Dict\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "from pydantic_ai import Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Workflow: Evaluator - Optimizer\n",
    "\n",
    "While executing a single call to an LLM with a good prompt and sufficient context\n",
    "often yields satisfactory results, the first run isn't always the best we can\n",
    "achieve. By iteratively getting the LLM to generate a result, and then evaluate\n",
    "the result and propose improvements, we can achieve much higher quality.\n",
    "\n",
    "> <img src=\"https://ai.pydantic.dev/img/pydantic-ai-dark.svg\" style=\"height: 1em;\" />\n",
    "> The schema definition derived from the Pydantic models we define is primarily\n",
    "> used to control the result we read from the LLM call, but in many cases it\n",
    "> is also possible to use it to instruct the LLM on the desired behaviour.\n",
    "> Here, for example, we use a `thoughts` field to get the LLM to engage in\n",
    "> \"chain-of-thought\" generation, which helps it in reasoning. By generating the\n",
    "> content of this field, the LLM directs itself towards a more detailed and precise\n",
    "> response. Even if we don't need to read the value generated, we can still inspect\n",
    "> it in debugging or using an observability tool like Pydantic Logfire to understand\n",
    "> how the LLM approaches the challenge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeneratorResponse(BaseModel):\n",
    "    thoughts: str = Field(..., description=(\n",
    "        'Your understanding of the task and feedback '\n",
    "        'and how you plan to improve.'\n",
    "    ))\n",
    "    response: str = Field(..., description='The generated solution.')\n",
    "\n",
    "\n",
    "async def generate(prompt: str, task: str, context: str = \"\") -> tuple[str, str]:\n",
    "    \"\"\"Generate and improve a solution based on feedback.\"\"\"\n",
    "    system_prompt = prompt\n",
    "    if context:\n",
    "        system_prompt += f\"\\n\\n{context}\"\n",
    "\n",
    "    generator_agent = Agent(\n",
    "        AI_MODEL,\n",
    "        system_prompt=system_prompt,\n",
    "        output_type=GeneratorResponse,\n",
    "    )\n",
    "    response = await generator_agent.run(f'Task:\\n{task}')\n",
    "\n",
    "    thoughts = response.output.thoughts\n",
    "    result = response.output.response\n",
    "    \n",
    "    show('', title='Generation')\n",
    "    show(thoughts, title='Thoughts')\n",
    "    show(result, title='Generated')\n",
    "    \n",
    "    return thoughts, result\n",
    "\n",
    "\n",
    "class EvaluatorResponse(BaseModel):\n",
    "    thoughts: str = Field(..., description=(\n",
    "        'Your careful and detailed review and evaluation of the submited content.'\n",
    "    ))\n",
    "    evaluation: str = Field(..., description='PASS, NEEDS_IMPROVEMENT, or FAIL')\n",
    "    feedback: str = Field(..., description='What needs improvement and why.')\n",
    "\n",
    "\n",
    "async def evaluate(prompt: str, content: str, task: str) -> tuple[str, str]:\n",
    "    \"\"\"Evaluate if a solution meets requirements.\"\"\"\n",
    "    evaluator_agent = Agent(\n",
    "        AI_MODEL,\n",
    "        system_prompt=f'{prompt}\\n\\nTask:\\n{task}',\n",
    "        output_type=EvaluatorResponse,\n",
    "    )\n",
    "    response = await evaluator_agent.run(content)\n",
    "    evaluation = response.output.evaluation\n",
    "    feedback = response.output.feedback\n",
    "    \n",
    "    show('', title='Evaluation')\n",
    "    show(evaluation, title='Status')\n",
    "    show(feedback, title='Feedback')\n",
    "    \n",
    "    return evaluation, feedback\n",
    "\n",
    "\n",
    "async def loop(\n",
    "        task: str, evaluator_prompt: str, generator_prompt: str\n",
    "    ) -> tuple[str, list[dict]]:\n",
    "    \"\"\"Keep generating and evaluating until requirements are met.\"\"\"\n",
    "    memory = []\n",
    "    chain_of_thought = []\n",
    "    \n",
    "    thoughts, result = await generate(generator_prompt, task)\n",
    "    memory.append(result)\n",
    "    chain_of_thought.append({\"thoughts\": thoughts, \"result\": result})\n",
    "    \n",
    "    while True:\n",
    "        evaluation, feedback = await evaluate(evaluator_prompt, result, task)\n",
    "        if evaluation == \"PASS\":\n",
    "            return result, chain_of_thought\n",
    "            \n",
    "        context = \"\\n\".join([\n",
    "            \"Previous attempts:\",\n",
    "            *[f\"- {m}\" for m in memory],\n",
    "            f\"\\nFeedback: {feedback}\"\n",
    "        ])\n",
    "        \n",
    "        thoughts, result = await generate(generator_prompt, task, context)\n",
    "        memory.append(result)\n",
    "        chain_of_thought.append({\"thoughts\": thoughts, \"result\": result})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Generation"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Thoughts"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "```\n",
       "To address the task, I'll create a stack implementation in Python that handles the regular push and pop operations while also maintaining a minimum stack to allow the getMin operation to be O(1). The push operation will involve adding elements to both the main stack and the min stack (only if the current element is the new minimum so far). The pop operation will involve removing elements from both stacks. By maintaining both a stack and a min stack, we can ensure that getMin can be performed in constant time.\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Generated"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "```python\n",
       "class MinStack:\n",
       "    def __init__(self):\n",
       "        self.stack = []\n",
       "        self.min_stack = []\n",
       "\n",
       "    def push(self, x):\n",
       "        \"\"\"Pushes an element onto the stack and updates the min stack.\"\"\"\n",
       "        self.stack.append(x)\n",
       "        if not self.min_stack or x <= self.min_stack[-1]:\n",
       "            self.min_stack.append(x)\n",
       "\n",
       "    def pop(self):\n",
       "        \"\"\"Removes the element on top of the stack and updates the min stack.\"\"\"\n",
       "        if not self.stack:\n",
       "            return None\n",
       "\n",
       "        top_element = self.stack.pop()\n",
       "        if top_element == self.min_stack[-1]:\n",
       "            self.min_stack.pop()\n",
       "        return top_element\n",
       "\n",
       "    def getMin(self):\n",
       "        \"\"\"Gets the minimum element in the stack.\"\"\"\n",
       "        if not self.min_stack:\n",
       "            return None\n",
       "        return self.min_stack[-1]\n",
       "\n",
       "In this implementation:\n",
       "- `push(x)` adds the element `x` to the main stack and updates the `min_stack` if `x` is less than or equal to the current minimum.\n",
       "- `pop()` removes the last element from the main stack and also checks if it corresponds to the current minimum to maintain the `min_stack`.\n",
       "- `getMin()` simply returns the element at the top of `min_stack`, which is the current minimum in the stack. \n",
       "\n",
       "All operations are executed in O(1) time complexity."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Evaluation"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Status"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "```\n",
       "PASS\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Feedback"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "```\n",
       "The implementation is solidly designed and fulfills all the requirements of the task. If you'd like to improve it further:\n",
       "1. Consider handling edge cases or invalid operations, such as popping from an empty stack, by raising exceptions rather than returning None, aligning with typical stack behavior.\n",
       "2. Continue to maintain clear documentation and appropriate error handling in production-level code, especially for critical data structures like a stack.\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Final Result"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "```python\n",
       "class MinStack:\n",
       "    def __init__(self):\n",
       "        self.stack = []\n",
       "        self.min_stack = []\n",
       "\n",
       "    def push(self, x):\n",
       "        \"\"\"Pushes an element onto the stack and updates the min stack.\"\"\"\n",
       "        self.stack.append(x)\n",
       "        if not self.min_stack or x <= self.min_stack[-1]:\n",
       "            self.min_stack.append(x)\n",
       "\n",
       "    def pop(self):\n",
       "        \"\"\"Removes the element on top of the stack and updates the min stack.\"\"\"\n",
       "        if not self.stack:\n",
       "            return None\n",
       "\n",
       "        top_element = self.stack.pop()\n",
       "        if top_element == self.min_stack[-1]:\n",
       "            self.min_stack.pop()\n",
       "        return top_element\n",
       "\n",
       "    def getMin(self):\n",
       "        \"\"\"Gets the minimum element in the stack.\"\"\"\n",
       "        if not self.min_stack:\n",
       "            return None\n",
       "        return self.min_stack[-1]\n",
       "\n",
       "In this implementation:\n",
       "- `push(x)` adds the element `x` to the main stack and updates the `min_stack` if `x` is less than or equal to the current minimum.\n",
       "- `pop()` removes the last element from the main stack and also checks if it corresponds to the current minimum to maintain the `min_stack`.\n",
       "- `getMin()` simply returns the element at the top of `min_stack`, which is the current minimum in the stack. \n",
       "\n",
       "All operations are executed in O(1) time complexity."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Chain of Thought"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "```\n",
       "[{'result': '```python\\n'\n",
       "            'class MinStack:\\n'\n",
       "            '    def __init__(self):\\n'\n",
       "            '        self.stack = []\\n'\n",
       "            '        self.min_stack = []\\n'\n",
       "            '\\n'\n",
       "            '    def push(self, x):\\n'\n",
       "            '        \"\"\"Pushes an element onto the stack and updates the min '\n",
       "            'stack.\"\"\"\\n'\n",
       "            '        self.stack.append(x)\\n'\n",
       "            '        if not self.min_stack or x <= self.min_stack[-1]:\\n'\n",
       "            '            self.min_stack.append(x)\\n'\n",
       "            '\\n'\n",
       "            '    def pop(self):\\n'\n",
       "            '        \"\"\"Removes the element on top of the stack and updates '\n",
       "            'the min stack.\"\"\"\\n'\n",
       "            '        if not self.stack:\\n'\n",
       "            '            return None\\n'\n",
       "            '\\n'\n",
       "            '        top_element = self.stack.pop()\\n'\n",
       "            '        if top_element == self.min_stack[-1]:\\n'\n",
       "            '            self.min_stack.pop()\\n'\n",
       "            '        return top_element\\n'\n",
       "            '\\n'\n",
       "            '    def getMin(self):\\n'\n",
       "            '        \"\"\"Gets the minimum element in the stack.\"\"\"\\n'\n",
       "            '        if not self.min_stack:\\n'\n",
       "            '            return None\\n'\n",
       "            '        return self.min_stack[-1]\\n'\n",
       "            '```\\n'\n",
       "            '\\n'\n",
       "            'In this implementation:\\n'\n",
       "            '- `push(x)` adds the element `x` to the main stack and updates '\n",
       "            'the `min_stack` if `x` is less than or equal to the current '\n",
       "            'minimum.\\n'\n",
       "            '- `pop()` removes the last element from the main stack and also '\n",
       "            'checks if it corresponds to the current minimum to maintain the '\n",
       "            '`min_stack`.\\n'\n",
       "            '- `getMin()` simply returns the element at the top of '\n",
       "            '`min_stack`, which is the current minimum in the stack. \\n'\n",
       "            '\\n'\n",
       "            'All operations are executed in O(1) time complexity.',\n",
       "  'thoughts': \"To address the task, I'll create a stack implementation in \"\n",
       "              'Python that handles the regular push and pop operations while '\n",
       "              'also maintaining a minimum stack to allow the getMin operation '\n",
       "              'to be O(1). The push operation will involve adding elements to '\n",
       "              'both the main stack and the min stack (only if the current '\n",
       "              'element is the new minimum so far). The pop operation will '\n",
       "              'involve removing elements from both stacks. By maintaining both '\n",
       "              'a stack and a min stack, we can ensure that getMin can be '\n",
       "              'performed in constant time.'}]\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluator_prompt = \"\"\"\n",
    "Evaluate this following code implementation for:\n",
    "1. Code correctness: does it implement what is required in the spec flawlessly?\n",
    "2. Time complexity: does the implementation meet the time complexity requirements?\n",
    "3. Efficiency: is the implementation the most efficient and optimized possible for the requirements?\n",
    "4. Style and best practices: does the code follow standard Python style and best practices?\n",
    "5. Readability: is the code easy to read and understand?\n",
    "6. Documentation: is the code clearly documented, with docstrings for all functions and classes, and with inline comments where necessary?\n",
    "\n",
    "You should be evaluating only and not attemping to solve the task.\n",
    "Evaluate the code carefully and critically and make sure you don't\n",
    "miss any opportunities for improvement.\n",
    "Only output \"PASS\" if all the evaluation criteria are met and you\n",
    "have no further suggestions for improvements, otherwise output\n",
    "\"NEEDS_IMPROVEMENT\" or \"FAIL\" so that the coder can learn and improve.\n",
    "\"\"\"\n",
    "\n",
    "generator_prompt = \"\"\"\n",
    "Your goal is to complete the task based on the user input. If there are feedback \n",
    "from your previous generations, you should reflect on them to improve your solution.\"\"\"\n",
    "\n",
    "task = \"\"\"\n",
    "Implement a Stack with:\n",
    "1. push(x)\n",
    "2. pop()\n",
    "3. getMin()\n",
    "All operations should be O(1).\n",
    "\"\"\"\n",
    "\n",
    "result, chain_of_thought = await loop(task, evaluator_prompt, generator_prompt)\n",
    "\n",
    "show(result, title='Final Result')\n",
    "show(chain_of_thought, title='Chain of Thought')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
